# Recognized-TBL-by-CNN

To ensure other researchers with no coding can implement our neural network, it was based on the open-source Deep Learning library implementation in The Konstanz Information Miner (KNIME) Analytics Platform. Preparing images is done by resizing each one to be compatible with each pre-trained CNNs image input layer. Each of the previous pre-trained networks has its input layer size: As mentioned earlier, a patch size of 30 was selected, and the images were resized to 224 × 224 for VGG16, VGG19, and DenseNet121, as well as to 150 × 150 for InceptionV3, Xception. After the preprocessing step, each cropped patch was fed into a convolutional neural network to extract the image features for classification. The workflow series is heavily inspired by the blog-post of François Chollet (see https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html). We upload the workflow file which could be replicate image preprocess program and recognition programs on KNIME 4.0.0 to Github (Take VGG16 as an example, the reader could easily extend to other algorithms). 
In order to run the workflow, the following KNIME extensions was installed, including 1) KNIME Deep Learning - Keras Integration (Labs); 2) KNIME Image Processing (Community Contributions Trusted); 3) KNIME Image Processing - Deep Learning Extension (Community Contributions Trusted); 4) KNIME Image Processing - Python Extension (Community Contributions Trusted); 5) KNIME Streaming Execution (Labs). The local python installation that includes Keras was installed followed https://www.knime.com/deeplearning#keras for installation recommendations and further information.
